[training_param]
# batchsize / num of gpus equals the batchsize per gpu
batchsize = 22
gpus = main=0
num_process = 11
seed = 0
train_iter = 260000
learning_rate = 0.007


## mpii dataset
[mpii]
images = ./data/images
annotations = ./data/mpii.json
parts_scale = 1.0x1.0
instance_scale = 2.0x2.0
train_size = 0.9
min_num_keypoints = 1
# Cache data on training may increase speed of training
# If you have rich machine which has more than 64 GB RAM, you may set `True`.
use_cache = False

## coco dataset
[coco]
train_images = ./data/train2017
train_annotations = ./data/annotations/person_keypoints_train2017.json
val_images = ./data/val2017
val_annotations = ./data/annotations/person_keypoints_val2017.json
parts_scale = 0.2x0.2
instance_scale = 1.0x1.0
min_num_keypoints = 5

[dataset]
# must be `mpii` or `coco`
type = mpii

[result]
dir = ./work/resnet18_384x384_mpii

[model_param]
# must be `mv2`, `resnet18`, `resnet34` or `resnet50`
model_name = resnet18

# input image size
insize = 384x384

# set W'xH' value. it must be odd values
local_grid_size = 9x9

# parameter of mobilenetv2
width_multiplier = 1.0

# set weight loss. see original paper for more detail
lambda_resp = 0.25
lambda_iou = 1.0
lambda_coor = 5.0
lambda_size = 5.0
lambda_limb = 0.5

[predict]
# If `False` is set, hide bbox of annotation other than human instance.
visbbox = True
# detection_thresh
detection_thresh = 0.15
# ignore human its num of keypoints is less than min_num_keypoints
min_num_keypoints= 1
